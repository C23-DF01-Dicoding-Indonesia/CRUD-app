# -*- coding: utf-8 -*-
"""Copy of semantic_search_demo_out_domain.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zT5gy3xtkLgCcscOXjIE8Wq_PUzHsQ4k
"""

from datasets import load_dataset, DatasetDict
from transformers import AutoTokenizer, TFXLMRobertaModel, TFAutoModel
import tensorflow as tf
from transformers import AutoTokenizer, AutoModel
import torch
from ast import literal_eval
import sys
from datasets import load_dataset

dataset = load_dataset("carlesoctav/auto-tag-ML-discussions-embbed", use_auth_token="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")

from transformers import AutoTokenizer, TFAutoModel

tokenizer = AutoTokenizer.from_pretrained("carlesoctav/multi-qa-en-id-mMiniLMv2-L6-H384")

model = TFAutoModel.from_pretrained("carlesoctav/multi-qa-en-id-mMiniLMv2-L6-H384")

dataset

docs = []
doc_embeddings =[]
max_docs = 100000

for doc in dataset["train"]:
    docs.append(doc)
    doc_embeddings.append(doc["target_embedding"])
    if len(docs) >= max_docs:
        break

doc_embeddings = tf.convert_to_tensor(doc_embeddings)

from collections import Counter
question_plus_title = sys.argv[1]
# question_plus_title = "karena digunakan kelas maka saya mencoba untuk menggunakan class mode categorical dan loss categorical crossentropy tetapi mengakibatkan akurasi validasinya konstan di mengapa terimakasih"

response = tokenizer(question_plus_title, padding="max_length", truncation=True, max_length=256, return_tensors="tf")
query_embedding = model(response).last_hidden_state[:,0,:]

top_k_param = 10 # try to change this also

# Compute dot score between query embedding and document embeddings
dot_scores_search = tf.matmul(query_embedding, doc_embeddings, transpose_b=True)
top_k_modules = tf.math.top_k(dot_scores_search, k=top_k_param)

list_tags_relevant = []

print("Query:", question_plus_title)
for doc_id in top_k_modules.indices[0]:
  a = docs[doc_id]["tags"].split(",")
  a[0] = a[0][1:]
  a[-1] = a[-1][:-1]
  for i in a:
    list_tags_relevant.append(i)


counts = Counter(list_tags_relevant)
top_5 = zip(*counts.most_common(5))
suggested_tags = str(list(top_5)[0])

print(counts)
print('suggested tag are:',suggested_tags)

import json
from sorcery import dict_of

data = dict_of(question_plus_title, suggested_tags)
with open('./tag.json', 'w', encoding='utf-8') as f:
    json.dump(data, f, ensure_ascii=False, indent=4)